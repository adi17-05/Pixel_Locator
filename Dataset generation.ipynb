{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a588dec5",
   "metadata": {},
   "source": [
    "# Dataset Generation — Pixel Coordinate Regression (TFRecord, 150,000 samples)\n",
    "\n",
    "This notebook/script generates a synthetic dataset for the task:\n",
    "\n",
    "**Input:** 50×50 grayscale image with exactly one bright pixel (=255), all others 0  \n",
    "**Output label:** (x, y) coordinate of the bright pixel\n",
    "\n",
    "We store the dataset in **TFRecord shards** for efficient loading with TensorFlow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822785c3",
   "metadata": {},
   "source": [
    "## Why synthetic data?\n",
    "\n",
    "This problem is perfectly defined and does not require real-world images.\n",
    "\n",
    "Synthetic generation is ideal because:\n",
    "- Labels are **exact and error-free**\n",
    "- Dataset size can be increased easily (here: 150,000 samples)\n",
    "- Positions can be sampled **uniformly** so all coordinates are equally represented\n",
    "- Enables fast experimentation and reproducible results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db768f6b",
   "metadata": {},
   "source": [
    "## Cell 1 — Imports and dependencies\n",
    "\n",
    "This cell imports all required libraries for dataset generation:\n",
    "\n",
    "- `numpy` for random coordinate generation and split indices\n",
    "- `tensorflow` for TFRecord writing and tensor serialization\n",
    "- `json` and `pathlib` for saving dataset metadata and output paths\n",
    "\n",
    "> If TensorFlow is not installed, install it before running:\n",
    "> `pip install tensorflow`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e727aff-1d16-4865-9904-4988796d5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d3aa77",
   "metadata": {},
   "source": [
    "## Cell 2 — Core dataset generation utilities (TFRecord + splits + metadata)\n",
    "\n",
    "This cell defines the full dataset generation pipeline:\n",
    "\n",
    "### What this cell contains\n",
    "1. **`make_splits()`**\n",
    "   - Creates reproducible shuffled indices for:\n",
    "     - train (80%)\n",
    "     - validation (10%)\n",
    "     - test (10%)\n",
    "\n",
    "2. **TFRecord helper functions**\n",
    "   - Creates TFRecord `Feature` objects for saving bytes and integer values.\n",
    "\n",
    "3. **`write_tfrecord_dataset()`**\n",
    "   - Generates `n_samples` images of size `img_size × img_size`\n",
    "   - For each sample:\n",
    "     - Picks a random coordinate `(x, y)` uniformly from `[0, 49]`\n",
    "     - Creates an image with exactly one bright pixel: `image[y, x] = bright_value`\n",
    "     - Serializes the image using `tf.io.serialize_tensor`\n",
    "     - Writes data into sharded TFRecord files\n",
    "\n",
    "4. **Outputs created**\n",
    "   - TFRecord shard files: `data-xxxxx-of-yyyyy.tfrecord`\n",
    "   - Split index files: `split_train_idx.npy`, `split_val_idx.npy`, `split_test_idx.npy`\n",
    "   - Metadata file: `meta.json` (image size, bright value, compression, coordinate convention)\n",
    "\n",
    "### Coordinate convention\n",
    "We store labels as `(x, y)` where:\n",
    "- `x` = column index\n",
    "- `y` = row index\n",
    "- and the bright pixel is placed using: `image[y, x] = bright_value`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ea9a22-d18a-4ba9-9ebc-67e0026c79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_splits(\n",
    "    n_samples: int,\n",
    "    seed: int = 42,\n",
    "    train_ratio: float = 0.80,\n",
    "    val_ratio: float = 0.10\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    if train_ratio + val_ratio >= 1.0:\n",
    "        raise ValueError(\"train_ratio + val_ratio must be < 1.0\")\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(n_samples, dtype=np.int64)\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    n_train = int(n_samples * train_ratio)\n",
    "    n_val = int(n_samples * val_ratio)\n",
    "\n",
    "    return {\n",
    "        \"train\": idx[:n_train],\n",
    "        \"val\": idx[n_train:n_train + n_val],\n",
    "        \"test\": idx[n_train + n_val:]\n",
    "    }\n",
    "\n",
    "\n",
    "def _bytes_feature(value: bytes) -> tf.train.Feature:\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value: int) -> tf.train.Feature:\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def write_tfrecord_dataset(\n",
    "    out_dir: str = \"Pixel_dataset\",\n",
    "    n_samples: int = 150_000,\n",
    "    img_size: int = 50,\n",
    "    bright_value: int = 255,\n",
    "    shard_size: int = 15_000,\n",
    "    seed: int = 42,\n",
    "    compression: str = \"GZIP\",\n",
    ") -> None:\n",
    "    out_path = Path(out_dir)\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    n_shards = (n_samples + shard_size - 1) // shard_size\n",
    "    options = tf.io.TFRecordOptions(compression_type=compression) if compression else None\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    total_written = 0\n",
    "\n",
    "    for shard_id in range(n_shards):\n",
    "        start = shard_id * shard_size\n",
    "        end = min(start + shard_size, n_samples)\n",
    "        batch_n = end - start\n",
    "\n",
    "        # Generate labels with NumPy (simple + fast)\n",
    "        xs = rng.integers(0, img_size, size=batch_n, dtype=np.int16)\n",
    "        ys = rng.integers(0, img_size, size=batch_n, dtype=np.int16)\n",
    "\n",
    "        shard_name = f\"data-{shard_id:05d}-of-{n_shards:05d}.tfrecord\"\n",
    "        shard_file = out_path / shard_name\n",
    "\n",
    "        with tf.io.TFRecordWriter(str(shard_file), options=options) as writer:\n",
    "            for i in range(batch_n):\n",
    "                # Build one image (uint8)\n",
    "                img = np.zeros((img_size, img_size), dtype=np.uint8)\n",
    "                img[int(ys[i]), int(xs[i])] = np.uint8(bright_value)\n",
    "\n",
    "                # Serialize safely (TensorFlow-native)\n",
    "                img_tensor = tf.convert_to_tensor(img, dtype=tf.uint8)\n",
    "                img_bytes = tf.io.serialize_tensor(img_tensor).numpy()\n",
    "\n",
    "                example = tf.train.Example(\n",
    "                    features=tf.train.Features(\n",
    "                        feature={\n",
    "                            \"image_tensor\": _bytes_feature(img_bytes),\n",
    "                            \"x\": _int64_feature(int(xs[i])),\n",
    "                            \"y\": _int64_feature(int(ys[i])),\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "                writer.write(example.SerializeToString())\n",
    "\n",
    "        total_written += batch_n\n",
    "        print(f\"Wrote shard {shard_id + 1}/{n_shards}: {batch_n} samples (total {total_written}/{n_samples})\")\n",
    "\n",
    "    # Save split indices\n",
    "    splits = make_splits(n_samples=n_samples, seed=seed, train_ratio=0.80, val_ratio=0.10)\n",
    "    np.save(out_path / \"split_train_idx.npy\", splits[\"train\"])\n",
    "    np.save(out_path / \"split_val_idx.npy\", splits[\"val\"])\n",
    "    np.save(out_path / \"split_test_idx.npy\", splits[\"test\"])\n",
    "\n",
    "    # Save metadata\n",
    "    meta = {\n",
    "        \"n_samples\": n_samples,\n",
    "        \"img_size\": img_size,\n",
    "        \"bright_value\": bright_value,\n",
    "        \"shard_size\": shard_size,\n",
    "        \"n_shards\": n_shards,\n",
    "        \"compression\": compression,\n",
    "        \"coord_convention\": \"labels are (x, y) where image[y, x] = bright_value\",\n",
    "        \"feature_schema\": {\n",
    "            \"image_tensor\": \"tf.io.serialize_tensor(uint8[50,50])\",\n",
    "            \"x\": \"int64\",\n",
    "            \"y\": \"int64\"\n",
    "        }\n",
    "    }\n",
    "    (out_path / \"meta.json\").write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(\"\\n✅ Dataset generation complete:\", out_path.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66db6430",
   "metadata": {},
   "source": [
    "## Cell 3 — Generate the dataset (150,000 samples)\n",
    "\n",
    "This cell runs the dataset generator with the chosen configuration:\n",
    "\n",
    "- Output folder: `Pixel_dataset`\n",
    "- Total samples: `150,000`\n",
    "- Image size: `50 × 50`\n",
    "- Bright pixel value: `255`\n",
    "- Sharding: `15,000` samples per TFRecord (≈ 10 shards)\n",
    "- Seed: `42` (reproducible)\n",
    "- Compression: `GZIP` (smaller files, faster I/O in many cases)\n",
    "\n",
    "After this cell finishes, the dataset files will be created inside `Pixel_dataset/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8adce-ea97-4e1e-a61e-0f76c7e63028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote shard 1/10: 15000 samples (total 15000/150000)\n",
      "Wrote shard 2/10: 15000 samples (total 30000/150000)\n",
      "Wrote shard 3/10: 15000 samples (total 45000/150000)\n",
      "Wrote shard 4/10: 15000 samples (total 60000/150000)\n",
      "Wrote shard 5/10: 15000 samples (total 75000/150000)\n",
      "Wrote shard 6/10: 15000 samples (total 90000/150000)\n",
      "Wrote shard 7/10: 15000 samples (total 105000/150000)\n",
      "Wrote shard 8/10: 15000 samples (total 120000/150000)\n",
      "Wrote shard 9/10: 15000 samples (total 135000/150000)\n",
      "Wrote shard 10/10: 15000 samples (total 150000/150000)\n",
      "\n",
      "✅ Dataset generation complete: C:\\Users\\adity\\Desktop\\DeepEdge\\Pixel_dataset\n"
     ]
    }
   ],
   "source": [
    "write_tfrecord_dataset(\n",
    "    out_dir=\"Pixel_dataset\",\n",
    "    n_samples=150_000,\n",
    "    img_size=50,\n",
    "    bright_value=255,\n",
    "    shard_size=15_000,\n",
    "    seed=42,\n",
    "    compression=\"GZIP\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a7e9ac",
   "metadata": {},
   "source": [
    "## Cell 4 — Sanity check (verify dataset integrity)\n",
    "\n",
    "This cell validates the generated dataset by reading TFRecords back and checking:\n",
    "\n",
    "1. TFRecord decoding works correctly (`tf.io.parse_tensor`)\n",
    "2. The label `(x, y)` matches the bright pixel location:\n",
    "   - `image[y, x] == bright_value`\n",
    "3. Runs the check for multiple samples (default: 30)\n",
    "\n",
    "If all checks pass, it prints a success message:\n",
    "✅ Sanity check passed\n",
    "\n",
    "This ensures the dataset is correct before using it in the training notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f03d08db-6838-48b5-b6d2-02b934b05f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sanity check passed for 30 samples\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def parse_example(example_proto, img_size: int):\n",
    "    feature_spec = {\n",
    "        \"image_tensor\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"x\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"y\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    ex = tf.io.parse_single_example(example_proto, feature_spec)\n",
    "\n",
    "    img = tf.io.parse_tensor(ex[\"image_tensor\"], out_type=tf.uint8)\n",
    "    img = tf.reshape(img, (img_size, img_size))\n",
    "\n",
    "    x = tf.cast(ex[\"x\"], tf.int32)\n",
    "    y = tf.cast(ex[\"y\"], tf.int32)\n",
    "    return img, x, y\n",
    "\n",
    "\n",
    "def sanity_check(dataset_dir: str, n_checks: int = 30):\n",
    "    meta = json.loads(Path(dataset_dir, \"meta.json\").read_text(encoding=\"utf-8\"))\n",
    "    img_size = meta[\"img_size\"]\n",
    "    bright = meta[\"bright_value\"]\n",
    "    compression = meta[\"compression\"]\n",
    "\n",
    "    files = sorted(glob.glob(str(Path(dataset_dir, \"*.tfrecord\"))))\n",
    "    ds = tf.data.TFRecordDataset(\n",
    "        files,\n",
    "        compression_type=compression if compression else None\n",
    "    ).map(lambda r: parse_example(r, img_size))\n",
    "\n",
    "    for i, (img, x, y) in enumerate(ds.take(n_checks), start=1):\n",
    "        val = int(img[int(y), int(x)].numpy())\n",
    "        if val != bright:\n",
    "            raise AssertionError(f\"Mismatch at sample {i}: img[y,x]={val}, expected {bright}\")\n",
    "\n",
    "    print(f\"✅ Sanity check passed for {n_checks} samples\")\n",
    "\n",
    "\n",
    "sanity_check(\"Pixel_dataset\", n_checks=30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
